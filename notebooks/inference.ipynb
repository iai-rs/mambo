{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "from src.models.ddpm import *\n",
    "from src.models.unet import Unet\n",
    "from src.models.ddpm_classifier_free import Unet as Unet_class\n",
    "from src.utils.image_utils import save_image_to_dir, save_patches_to_dir\n",
    "from src.utils.model_utils import (load_model, load_classifier_free_model, generate_whole_image, \n",
    "                                   create_lcl_ctx_channels, create_inputs, generate_patches, stitch_patches,\n",
    "                                   create_patch_channels)\n",
    "from src.config import IS_COND, OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load model for generating whole images in resolution 256x256\n",
    "whole_img_model_path = '../models/artifacts/vindr_healthy_256:v82/model_124499.pt'\n",
    "if IS_COND:\n",
    "    whole_image_model = load_classifier_free_model(whole_img_model_path, channels=1, num_classes=3)\n",
    "    img_class = 0\n",
    "else:\n",
    "    whole_image_model = load_model(whole_img_model_path, channels=1)\n",
    "    img_class = ''\n",
    "\n",
    "# load model for generating local contexts (mid-resolution images)\n",
    "local_context_model_path = '../models/artifacts/vindr_lcl_ctx_3072:v37/model_56999.pt'\n",
    "local_context_model = load_model(local_context_model_path, channels=3)\n",
    "\n",
    "patch_model_path = '../models/artifacts/vindr_3c_256_v2:v84/model_169999.pt'\n",
    "patch_model = load_model(patch_model_path, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = generate_whole_image(whole_image_model, device, batch_size=1, img_class=img_class)\n",
    "save_image_to_dir(img, '../images/whole_small.png')\n",
    "plt.imshow(img[0], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_channels, patch_coords = create_lcl_ctx_channels(img, overlap=OVERLAP)\n",
    "print(len(img_channels))\n",
    "inputs, black_idx = create_inputs(img, img_channels, patch_coords, mask_shape=1024)\n",
    "print(len(inputs), len(black_idx))\n",
    "local_contexts = generate_patches(local_context_model, inputs, black_idx, timesteps=timesteps, overlap=OVERLAP, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_img = stitch_patches(local_contexts, overlap=0.125)\n",
    "plt.imshow(mid_img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_to_dir(mid_img, '../images/mid_img.png')\n",
    "save_patches_to_dir(local_contexts, '../images/local_contexts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_channels, patch_coords = create_patch_channels(torch.from_numpy(mid_img).unsqueeze(0), img, overlap=OVERLAP)\n",
    "inputs, black_idx = create_inputs(img, img_channels, patch_coords, mask_shape=3072)\n",
    "print(len(inputs), len(black_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = generate_patches(patch_model, inputs, black_idx, timesteps=timesteps, overlap=OVERLAP, device=device)\n",
    "final_img = stitch_patches(patches, overlap=OVERLAP)\n",
    "plt.imshow(final_img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_to_dir(final_img,  '../images/final_img.png')\n",
    "save_patches_to_dir(patches, '../images/patches')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mammo-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
